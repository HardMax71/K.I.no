{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the raw data concise and appending metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Included Metadata:\n",
    "    -Rating\n",
    "    -Weekday\n",
    "    -Semester\n",
    "    -Age\n",
    "    -Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"999ff2a141d82575eae2cd20f2aad315\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will always just look at the first result of the API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_movies(movie_search):\n",
    "    response = requests.get(\n",
    "        f\"https://api.themoviedb.org/3/search/movie?api_key={API_KEY}\"\n",
    "        f\"&query={string_to_query(movie_search)}\")\n",
    "    return response.json()['results']\n",
    "\n",
    "def string_to_query(search):\n",
    "    return search.replace(\" \", \"+\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sessions allow for faster requests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_title_ambiguity(result_list):\n",
    "    # check if there are more than 1 results\n",
    "    title_list = [x['title'] for x in result_list]\n",
    "\n",
    "    check = title_list.pop(0)\n",
    "    for title in title_list:\n",
    "        if check == title:\n",
    "            if check_first_of_his_name(result_list):\n",
    "                return False\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# if first release with name, don't append year in link\n",
    "def check_first_of_his_name(result_list):\n",
    "    release_list = [get_release_date(x) for x in result_list]\n",
    "    if release_list[0] == min(release_list):\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def get_release_date(movie):\n",
    "    try:\n",
    "        date = datetime.strptime(movie['release_date'], '%Y-%m-%d').date()\n",
    "    except:\n",
    "        date = datetime.today().date()\n",
    "    return date\n",
    "\n",
    "def get_genre(movie):\n",
    "    return movie['genre_ids']\n",
    "\n",
    "def get_tmdb_title(movie):\n",
    "    return movie['title']\n",
    "\n",
    "def get_link(result_list):\n",
    "    \n",
    "    title = get_tmdb_title(result_list[0])\n",
    "    # if Title is ambiguous put release year on end of string\n",
    "    if check_title_ambiguity(result_list):\n",
    "        # first 4 digits are year (yyyy-mm-dd)\n",
    "        title = title + \" \" + str(get_release_date(result_list[0]).year)\n",
    "\n",
    "    # remove dots etc.\n",
    "    fit = re.sub(\"[,./()\\-;:_#'+*~?!&]\", \"\", title)\n",
    "    # turn everything lower case\n",
    "    fit = fit.lower()\n",
    "    # turn whitespaces to -\n",
    "    fit = re.sub(\" \", \"-\", fit)\n",
    "\n",
    "    link = f'https://letterboxd.com/film/{fit}'\n",
    "    return link\n",
    "\n",
    "def get_letterboxd_rating(result_list):\n",
    "    url = get_link(result_list)\n",
    "    html = s.get(url)\n",
    "    junk = BeautifulSoup(html.content, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        # rating is hidden in <meta> tag named twitter:data2\n",
    "        results = junk.find('meta', {\"name\": \"twitter:data2\", \"content\": True})\n",
    "        # remove everything after first whitespace \"3.5 out of 5\" but we only want 3.5\n",
    "        rating = re.search('\\S+', results['content']).group()\n",
    "        return float(rating)\n",
    "    # Incase the movie does not have a rating on Letterboxd\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_metadata_string(result_list):\n",
    "    return f\"Title: {get_tmdb_title(result_list[0])}\\nRelease-date: {get_release_date(result_list[0])}\\nRating: {get_letterboxd_rating(result_list)}\\nLetterboxd Link: {get_link(result_list)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_date(string, format = '%d.%m.%y'):\n",
    "    return datetime.strptime(string, format).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Good Vibrations\n",
      "Release-date: 2012-05-31\n",
      "Rating: None\n",
      "Letterboxd Link: https://letterboxd.com/film/good-vibrations-2012\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "result_list = find_movies(\"Good Vibrations\")\n",
    "print(movie_metadata_string(result_list))\n",
    "print(check_title_ambiguity(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"CineAsta_Movie_Data_Raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Date'] = raw_data['Date'].apply(str_to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_dates = pd.read_csv(\"~/Projekte/Movie_Attendence_Prediction/Data/Semester_Dates/Semester_Dates.csv\", sep=\"\\t\", encoding= \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_dates['Beginn'] = term_dates['Beginn'].apply(str_to_date, format = '%d.%m.%Y')\n",
    "term_dates['Ende'] = term_dates['Ende'].apply(str_to_date, format = '%d.%m.%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_semester(date):\n",
    "    check = (term_dates[\"Beginn\"] <= date) & (term_dates[\"Ende\"] >= date)\n",
    "    #horrible solution i hate this, there must be something better\n",
    "    return term_dates[\"Semester\"][check].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Semester'] = raw_data['Date'].apply(add_semester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_weekday(date):\n",
    "    return calendar.day_name[date.weekday()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Weekday'] = raw_data['Date'].apply(date_to_weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Date</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEN</td>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>10</td>\n",
       "      <td>Wintersemester 2022/23</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vortex</td>\n",
       "      <td>2023-02-07</td>\n",
       "      <td>2</td>\n",
       "      <td>Wintersemester 2022/23</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Triangle of Sadness</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>25</td>\n",
       "      <td>Wintersemester 2022/23</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wo in Paris die Sonne aufgeht</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>4</td>\n",
       "      <td>Wintersemester 2022/23</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Top Gun Maverick</td>\n",
       "      <td>2023-01-26</td>\n",
       "      <td>2</td>\n",
       "      <td>Wintersemester 2022/23</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The other Side of the River</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>8</td>\n",
       "      <td>Wintersemester 2022/23</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tomorrow</td>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>9</td>\n",
       "      <td>Wintersemester 2022/23</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Der beste Film aller Zeiten</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>1</td>\n",
       "      <td>Wintersemester 2022/23</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rabiye Kurnaz vs. George W. Bush</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>3</td>\n",
       "      <td>Wintersemester 2022/23</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Blutsauger</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>9</td>\n",
       "      <td>Wintersemester 2022/23</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Movie        Date  Attendance  \\\n",
       "0                               MEN  2023-02-08          10   \n",
       "1                            Vortex  2023-02-07           2   \n",
       "2               Triangle of Sadness  2023-02-01          25   \n",
       "3     Wo in Paris die Sonne aufgeht  2023-01-31           4   \n",
       "4                  Top Gun Maverick  2023-01-26           2   \n",
       "5       The other Side of the River  2023-01-25           8   \n",
       "6                          Tomorrow  2023-01-24           9   \n",
       "7       Der beste Film aller Zeiten  2023-01-18           1   \n",
       "8  Rabiye Kurnaz vs. George W. Bush  2023-01-17           3   \n",
       "9                       Blutsauger   2023-01-12           9   \n",
       "\n",
       "                 Semester    Weekday  \n",
       "0  Wintersemester 2022/23  Wednesday  \n",
       "1  Wintersemester 2022/23    Tuesday  \n",
       "2  Wintersemester 2022/23  Wednesday  \n",
       "3  Wintersemester 2022/23    Tuesday  \n",
       "4  Wintersemester 2022/23   Thursday  \n",
       "5  Wintersemester 2022/23  Wednesday  \n",
       "6  Wintersemester 2022/23    Tuesday  \n",
       "7  Wintersemester 2022/23  Wednesday  \n",
       "8  Wintersemester 2022/23    Tuesday  \n",
       "9  Wintersemester 2022/23   Thursday  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_movie_metadata(search):\n",
    "    result_list = find_movies(search)\n",
    "    \n",
    "    title = get_tmdb_title(result_list[0])\n",
    "    release_date = get_release_date(result_list[0])\n",
    "    rating = get_letterboxd_rating(result_list)\n",
    "    genre_ids = get_genre(result_list[0])\n",
    "\n",
    "    return title, release_date, rating, genre_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# return the metadata tuples to list and then dataframe, which can be appended \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m metadata \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\u001b[39mlist\u001b[39m(raw_data[\u001b[39m'\u001b[39;49m\u001b[39mMovie\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(add_movie_metadata)))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4521\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4525\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4526\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4527\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4630\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m, in \u001b[0;36madd_movie_metadata\u001b[0;34m(search)\u001b[0m\n\u001b[1;32m      4\u001b[0m title \u001b[39m=\u001b[39m get_tmdb_title(result_list[\u001b[39m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m release_date \u001b[39m=\u001b[39m get_release_date(result_list[\u001b[39m0\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m rating \u001b[39m=\u001b[39m get_letterboxd_rating(result_list)\n\u001b[1;32m      7\u001b[0m genre_ids \u001b[39m=\u001b[39m get_genre(result_list[\u001b[39m0\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m title, release_date, rating, genre_ids\n",
      "Cell \u001b[0;32mIn[5], line 54\u001b[0m, in \u001b[0;36mget_letterboxd_rating\u001b[0;34m(result_list)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_letterboxd_rating\u001b[39m(result_list):\n\u001b[1;32m     53\u001b[0m     url \u001b[39m=\u001b[39m get_link(result_list)\n\u001b[0;32m---> 54\u001b[0m     html \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39;49mget(url)\n\u001b[1;32m     55\u001b[0m     junk \u001b[39m=\u001b[39m BeautifulSoup(html\u001b[39m.\u001b[39mcontent, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     57\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m         \u001b[39m# rating is hidden in <meta> tag named twitter:data2\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:557\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[39m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    556\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 557\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:544\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    539\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    540\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    541\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    542\u001b[0m }\n\u001b[1;32m    543\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 544\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    546\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:679\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    677\u001b[0m     \u001b[39m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolve_redirects(r, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 679\u001b[0m     history \u001b[39m=\u001b[39m [resp \u001b[39mfor\u001b[39;00m resp \u001b[39min\u001b[39;00m gen]\n\u001b[1;32m    680\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    681\u001b[0m     history \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:679\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    677\u001b[0m     \u001b[39m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolve_redirects(r, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 679\u001b[0m     history \u001b[39m=\u001b[39m [resp \u001b[39mfor\u001b[39;00m resp \u001b[39min\u001b[39;00m gen]\n\u001b[1;32m    680\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    681\u001b[0m     history \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:237\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39myield\u001b[39;00m req\n\u001b[1;32m    235\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    238\u001b[0m         req,\n\u001b[1;32m    239\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    240\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    241\u001b[0m         verify\u001b[39m=\u001b[39;49mverify,\n\u001b[1;32m    242\u001b[0m         cert\u001b[39m=\u001b[39;49mcert,\n\u001b[1;32m    243\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    244\u001b[0m         allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    245\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49madapter_kwargs\n\u001b[1;32m    246\u001b[0m     )\n\u001b[1;32m    248\u001b[0m     extract_cookies_to_jar(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcookies, prepared_request, resp\u001b[39m.\u001b[39mraw)\n\u001b[1;32m    250\u001b[0m     \u001b[39m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:699\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[0;32m--> 699\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[1;32m    701\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py:831\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    830\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 831\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    833\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py:753\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    752\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 753\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    754\u001b[0m             \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m    755\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:572\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content):\n\u001b[1;32m    573\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[1;32m    574\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:764\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 764\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_chunk_length()\n\u001b[1;32m    765\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    766\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:694\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline()\n\u001b[1;32m    695\u001b[0m line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    696\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# return the metadata tuples to list and then dataframe, which can be appended \n",
    "\n",
    "metadata = pd.DataFrame(list(raw_data['Movie'].apply(add_movie_metadata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.columns =['TMDB_Title', 'Release_Date', 'Rating', 'Genre_IDs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.concat([raw_data, metadata], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Time_Since_Release'] = raw_data['Date'] - raw_data['Release_Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Time_Since_Release']= pd.to_timedelta(raw_data['Time_Since_Release'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
